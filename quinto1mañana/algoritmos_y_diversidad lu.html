<!DOCTYPE html>
<html lang="es">
<head> 
    <link rel="stylesheet" href="paginas.css">
    <meta charset="UTF-8">
    <title>Algoritmos y Diversidad</title>
    <div>
  <style>
    body {
      margin: 0;
      font-family: Arial, sans-serif;
    }
  
    .contenido {
      height: 2500px;
      padding: 40px;
      background: linear-gradient(white, lightgray);
    }
    
    /* Estilo del botón */
    #btnInicio {
      display: none; /* Oculto al inicio */
      position: fixed; /* Fijo en la pantalla */
      bottom: 30px; /* Modifica la posición vertical del botón */
      right: 30px; 
      z-index: 1000;
      font-size: 2px; /* Modifica la altura del botón (24) */
      border: none;
      border-radius: 5%;
      padding: 10px; /* Modifica el ancho del botón (15) */
      background-color: #d66868;
      color: white;
      cursor: pointer;
      box-shadow: 0 4px 6px rgba(0,0,0,0.3);
      transition: opacity 0.3s ease, transform 0.3s ease;
    }
    /* Cambia el color del botón cuando el cursor lo toca */
    #btnInicio:hover {
      background-color: #b95436;
      transform: scale(1.1);
    }
    
  </style>
   </div>
</head>
<body>
    <header>
        <h1>Algoritmos y Diversidad</h1>
        <h2>¿Cómo la Inteligencia Artificial Puede Reforzar o Combatir los Sesgos de Género y Sexuales?</h2>
    </header>
<main>
     <p>
        La inteligencia artificial, si bien ofrece avances increíbles, también puede perpetuar prejuicios existentes si no se desarrolla con cuidado.
        Cuando los datos usados para entrenar algoritmos están sesgados —por ejemplo, con menos representación de mujeres o personas LGBTQ+—,
        los sistemas pueden aprender y replicar esos mismos prejuicios. Sin embargo, al identificar estos problemas, también se abren
        oportunidades para usar la IA como herramienta para visibilizar desigualdades y promover la inclusión, si se diseñan modelos justos
        y representativos.
    </p>

    <img src="imagenes/racial-7822176_1280.jpg" width="80%">
    <h2>¿Cuándo Empezó la IA a Distinguir Entre un Hombre o una Mujer?</h2>
    <p>
        La inteligencia artificial empezó a tener conciencia sobre los sesgos de género y sexuales a partir de 2015 y especialmente desde 2018,
        cuando estudios demostraron que muchos sistemas eran discriminatorios, especialmente con mujeres y personas racializadas.
        Desde 2020 en adelante comienza un enfoque ético e inclusivo, reconociendo el género no binario y trabajando para reducir 
        sesgos en los algoritmos.
    </p>
    <img src="imagenes/inteligencia-artificial-articulo.jpg" width="80%">
    <h2>Experiencia con la IA Sobre Sesgos de Género</h2>

    <h2p>Sesgos en la Salud:</h2>

    <h3>Diagnósticos Erróneos de Enfermedades Cardíacas:</h3> 
    <p>
        Un estudio encontró que los algoritmos utilizados para diagnosticar enfermedades cardíacas tenían un sesgo de género, lo que resultó en un 50% más de probabilidades de diagnósticos erróneos en mujeres.
    </p>
<br>
    <h3>Detección de Cáncer de Mama:</h3>
    <p>
        Los algoritmos utilizados para detectar cáncer de mama mostraron una precisión del 93% en pacientes masculinos, pero solo del 86% en pacientes femeninas.
    </p>
<br>
    <h3>Diagnóstico de Enfermedades Autoinmunitarias:</h3>
    <p>
        Las mujeres tenían un 30% más de probabilidades de ser diagnosticadas incorrectamente que los hombres debido a sesgos en los algoritmos.
    </p>

    <h2>Sesgos en la Tecnología de Vigilancia</h2> 

    <h3>Sistema de Reconocimiento Facial de la Policía de Detroit:</h3> 
    <p>
        Un sistema de reconocimiento facial identificó incorrectamente a una mujer negra como sospechosa de robo, lo que sugiere un sesgo racial y de género.
    </p>
<br>
    <h3>Sistema de Vigilancia de la Ciudad de Nueva York:</h3>
    <p>
        Un informe encontró que el sistema tenía un sesgo de género, considerando más sospechosas a las mujeres en áreas monitoreadas.
    </p>
<br>
    <h3>Cámaras de Vigilancia en el Transporte Público:</h3>
    <p>
        Un estudio encontró que las cámaras de vigilancia en Londres eran más propensas a enfocarse en mujeres jóvenes que en hombres jóvenes.
    </p>

    <h2>Sesgos en Grandes Tecnológicas</h2>

    <h3>Amazon:</h3>
    <p>
        Un sistema de reclutamiento automatizado basado en IA penalizaba a los currículums que incluían palabras como "mujeres" 
        o referencias a clubes universitarios de mujeres.
    </p>
<br>
    <h3>Twitter o X:</h3> 
    <p>
        La IA utilizada para seleccionar fotos en las vistas previas de los tweets daba prioridad a los tweets que incluían fotos de hombres.
    </p>
<br> 
    <h3>Google:</h3> 
    <p>
        Un estudio encontró que la tecnología de reconocimiento de voz utilizada por Google Assistant tenía una tasa de error 1,5 veces mayor para las voces femeninas que para las masculinas.
    </p>
 
      </script>
      <style>
    .boton-seccion {
        background-color: #f8f9fa;
        color: black;
        padding: 20px;
        border-radius: 10px;
        cursor: pointer;
        transition: background-color 0.3s;
    }
    .boton-seccion:hover {
        background-color: rgba(0, 0, 0, 0.05);
    }
    
</style>

<section class="boton-seccion" onclick="window.location.href='index.html'"> 
    <h3>Volver a la Página Principal</h3>
</section>
</main>
<div>
  <!-- Botón que sigue al usuario -->
   <button onclick="scrollToTop()" id="btnInicio" title="Volver al inicio"><img src="imagenes/flecha hacia arriba.png" width="40px" height="40px"></button>

   <script> 
    // Detectar scroll
    window.addEventListener('scroll', function () {
      const btn = document.getElementById("btnInicio");
      if (window.scrollY > 150) {
        btn.style.display = "block";  // Aparece al bajar
      } else {
        btn.style.display = "none";   // Desaparece al volver arriba
      }
    });

    // Volver al inicio con el scroll 
    function scrollToTop() {
      window.scrollTo({
        top: 0,
        behavior: 'smooth'
      });
    }
   </script>
   <footer>
        <h5>Proyecto Tec. Inf. - 2025</h5>
   </footer>
</body>
</html>
